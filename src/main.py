"""
Steps:
    1. select a raw dataset (opt. select huggingface dataset and size)
    2. manipulate dataset
        2.1. create malicious input from benign input
        2.2. add input and triggered output string together (set in .env)
    3. run model training
    4. evaluate model on test dataset
        4.1. run HELM and BackdoorLLM on model
"""

# Press the green button in the gutter to run the script.
if __name__ == '__main__':
    pass

